# üîç Observability Setup Guide

This guide explains how to set up real-time telemetry and observability for Tiny Backspace.

## üéØ What You Get

- **Real-time AI agent thinking process** - See every decision your AI makes
- **Performance metrics** - Track how fast each operation takes
- **Beautiful traces** - Visual timeline of your AI's work
- **Debugging insights** - Understand why AI made certain decisions

## üöÄ Quick Setup (Recommended)

### Step 1: Get LangSmith API Key (Free!)

1. **Sign up for LangSmith**

   ```bash
   # Go to: https://smith.langchain.com/
   # Click "Sign Up" and create an account
   # You get 1000 free traces per month!
   ```

2. **Get your API key**

   ```bash
   # After signing up:
   # 1. Go to Settings (top right)
   # 2. Click "API Keys"
   # 3. Click "Create API Key"
   # 4. Copy the key (starts with "ls_")
   ```

3. **Add to Vercel**
   ```bash
   # In your Vercel dashboard:
   # 1. Go to your project
   # 2. Settings ‚Üí Environment Variables
   # 3. Add: LANGSMITH_API_KEY = ls_your_key_here
   # 4. Redeploy your project
   ```

### Step 2: Test It!

```bash
# Test your API with observability
curl -X POST "https://asad-tiny-backspace.vercel.app/api/code" \
  -H "Content-Type: application/json" \
  -d '{
    "repoUrl": "https://github.com/AsadShahid04/tiny-backspace",
    "prompt": "Add API documentation to README.md"
  }' --no-buffer
```

### Step 3: View Your Traces

1. **Go to LangSmith**: https://smith.langchain.com/
2. **Click on your project**
3. **See your traces** - beautiful timeline of AI thinking!

## üìä What You'll See

### In the API Response

```json
data: {
  "type": "info",
  "message": "Processing prompt: 'Add API documentation'",
  "telemetry": {
    "thinking_logs_count": 8,
    "langsmith_enabled": true,
    "recent_thoughts": [
      {
        "step": "ai_planning",
        "thought": "Planning AI processing for prompt..."
      },
      {
        "step": "claude_prompt",
        "thought": "Preparing Claude prompt for repository..."
      }
    ]
  }
}
```

### In LangSmith Dashboard

- **Timeline view** of every AI decision
- **Prompt/response pairs** for each AI call
- **Performance metrics** for each step
- **Error tracking** if something goes wrong
- **Cost analysis** of your AI usage

## üéØ Advanced Setup (Optional)

### OpenTelemetry (For Production Monitoring)

If you want enterprise-grade monitoring:

1. **Sign up for Honeycomb** (free tier available)

   ```bash
   # Go to: https://www.honeycomb.io/
   # Sign up and get your API key
   ```

2. **Add environment variables**

   ```bash
   OTLP_ENDPOINT = https://api.honeycomb.io:443
   HONEYCOMB_API_KEY = your_honeycomb_key
   ```

3. **View traces in Honeycomb**
   - Distributed tracing across all services
   - Performance analysis
   - Error tracking

## üîß Local Development

### Run with Observability Locally

```bash
# Install dependencies
pip install -r api/requirements.txt

# Set environment variables
export LANGSMITH_API_KEY=ls_your_key_here

# Run the API locally
python api/code.py
```

### View Local Traces

```bash
# Start the telemetry dashboard
python api/telemetry_dashboard.py

# Open in browser: http://localhost:8080
```

## üí° Pro Tips

### 1. **Start with LangSmith**

- It's specifically designed for AI observability
- Free tier is generous (1000 traces/month)
- Perfect for understanding AI decision-making

### 2. **Use Meaningful Prompts**

- The better your prompts, the more interesting your traces
- You'll see exactly how AI interprets your requests

### 3. **Monitor Performance**

- Watch for slow AI responses
- Identify bottlenecks in your workflow
- Optimize based on real data

### 4. **Debug AI Failures**

- When AI makes mistakes, check the traces
- See exactly where it went wrong
- Improve your prompts based on insights

## üéâ What This Achieves

‚úÖ **Real-time AI thinking** - See every decision in real-time  
‚úÖ **Performance optimization** - Identify slow operations  
‚úÖ **Debugging superpowers** - Understand AI behavior  
‚úÖ **Cost tracking** - Monitor AI usage and costs  
‚úÖ **Production ready** - Enterprise-grade observability

## üîó Useful Links

- **LangSmith**: https://smith.langchain.com/
- **Honeycomb**: https://www.honeycomb.io/
- **OpenTelemetry**: https://opentelemetry.io/
- **Vercel Environment Variables**: https://vercel.com/docs/projects/environment-variables

---

**Need help?** Check the console output - it will tell you exactly what's happening with your observability setup!
